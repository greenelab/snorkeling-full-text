{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the discriminator Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step following training is to evaluate the discriminator model performance. This notebook is designed generate results from training however; it isn't designed executed locally without a gpu. This notebook holds the code in a similar format and was trained on UPenn's computing cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from sklearn.metrics import auc, precision_recall_curve, roc_curve\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Train BioBert as Discriminator Model. Use these two commands to run the model.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--edge_type\",\n",
    "    help=\"The edge type to use to predict the sentences. Valid options are DaG, CbG, CtD, GiG\",\n",
    ")\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.edge_type.lower() == \"dag\":\n",
    "    edge_prediction = \"DaG\"\n",
    "    curated_label = \"curated_dsh\"\n",
    "\n",
    "    validation_file = \"DaG/training_sen/dg_dev_test_encoded_lemmas.tsv\"\n",
    "\n",
    "    entity_replace_one = \"DISEASE_ENTITY\"\n",
    "    one_replace = \"@DISEASE$\"\n",
    "    entity_replace_two = \"GENE_ENTITY\"\n",
    "    two_replace = \"@GENE$\"\n",
    "\n",
    "if args.edge_type.lower() == \"ctd\":\n",
    "    edge_prediction = \"CtD\"\n",
    "    curated_label = \"curated_ctd\"\n",
    "\n",
    "    validation_file = \"CtD/training_sen/cd_dev_test_encoded_lemmas.tsv\"\n",
    "\n",
    "    entity_replace_one = \"COMPOUND_ENTITY\"\n",
    "    one_replace = \"@CHEMICAL$\"\n",
    "    entity_replace_two = \"DISEASE_ENTITY\"\n",
    "    two_replace = \"@DISEASE$\"\n",
    "\n",
    "if args.edge_type.lower() == \"cbg\":\n",
    "    edge_prediction = \"CbG\"\n",
    "    curated_label = \"curated_cbg\"\n",
    "\n",
    "    validation_file = \"CbG/training_sen/cg_dev_test_encoded_lemmas.tsv\"\n",
    "\n",
    "    entity_replace_one = \"COMPOUND_ENTITY\"\n",
    "    one_replace = \"@CHEMICAL$\"\n",
    "    entity_replace_two = \"GENE_ENTITY\"\n",
    "    two_replace = \"@GENE$\"\n",
    "\n",
    "if args.edge_type.lower() == \"gig\":\n",
    "    edge_prediction = \"GiG\"\n",
    "    curated_label = \"curated_gig\"\n",
    "\n",
    "    validation_file = \"GiG/training_sen/gg_dev_test_encoded_lemmas.tsv\"\n",
    "\n",
    "    entity_replace_one = \"GENE_ENTITY\"\n",
    "    one_replace = \"@GENE$\"\n",
    "    entity_replace_two = \"GENE_ENTITY\"\n",
    "    two_replace = \"@GENE$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"../biobert-base-cased-v1.1\", local_files_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the datasets\n",
    "\n",
    "## Validation\n",
    "validation_data = pd.read_csv(validation_file, sep=\"\\t\").rename(\n",
    "    index=str, columns={\"split\": \"dataset\", curated_label: \"labels\"}\n",
    ")\n",
    "dev_split_id = validation_data.dataset.min()\n",
    "test_split_id = validation_data.dataset.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = Dataset.from_pandas(\n",
    "    validation_data.query(f\"dataset=={dev_split_id}\")[[\"parsed_lemmas\", \"labels\"]]\n",
    ")\n",
    "\n",
    "validation_dataset = validation_dataset.map(\n",
    "    lambda x: tokenizer(\n",
    "        \" \".join(\n",
    "            x[\"parsed_lemmas\"]\n",
    "            .replace(entity_replace_one, one_replace)\n",
    "            .replace(entity_replace_two, two_replace)\n",
    "            .split(\"|\")\n",
    "        ),\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=100,\n",
    "        truncation=True,\n",
    "    ),\n",
    "    remove_columns=[\"parsed_lemmas\"],\n",
    ")\n",
    "\n",
    "validation_dataset_pt = DataLoader(validation_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset.from_pandas(\n",
    "    validation_data.query(f\"dataset=={test_split_id}\")[[\"parsed_lemmas\", \"labels\"]]\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda x: tokenizer(\n",
    "        \" \".join(\n",
    "            x[\"parsed_lemmas\"]\n",
    "            .replace(entity_replace_one, one_replace)\n",
    "            .replace(entity_replace_two, two_replace)\n",
    "            .split(\"|\")\n",
    "        ),\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=100,\n",
    "        truncation=True,\n",
    "    ),\n",
    "    remove_columns=[\"parsed_lemmas\"],\n",
    ")\n",
    "\n",
    "test_dataset_pt = DataLoader(test_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for model_file in list(Path(args.edge_type).rglob(\"*/*model\")):\n",
    "\n",
    "    lf_num = int(re.search(r\"(\\d+)\", str(model_file)).groups()[0])\n",
    "    biobert = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_file, local_files_only=True, num_labels=2\n",
    "    )\n",
    "\n",
    "    # biobert = torch.nn.DataParallel(biobert)\n",
    "    # biobert = biobert.cuda()\n",
    "\n",
    "    biobert.eval()\n",
    "    validation_loss = []\n",
    "    predictions = []\n",
    "    val_labels = []\n",
    "\n",
    "    for idx, batch in tqdm.tqdm(enumerate(validation_dataset_pt)):\n",
    "        attention_mask = torch.stack(batch[\"attention_mask\"][0]).permute(\n",
    "            1, 0\n",
    "        )  # .cuda()\n",
    "        input_ids = torch.stack(batch[\"input_ids\"][0]).permute(1, 0)  # .cuda()\n",
    "        labels = batch[\"labels\"].long()  # .cuda()\n",
    "        output = biobert(\n",
    "            attention_mask=attention_mask, input_ids=input_ids, labels=labels\n",
    "        )\n",
    "\n",
    "        predictions.append(\n",
    "            torch.nn.functional.softmax(output[1], dim=1)[:, 1]\n",
    "        )  # .cpu())\n",
    "        val_labels.append(batch[\"labels\"])  # .cpu())\n",
    "        validation_loss.append(output[0].mean().item())\n",
    "\n",
    "        combined_labels = torch.cat(val_labels).numpy()\n",
    "        combined_predictions = torch.cat(predictions).detach().numpy()\n",
    "\n",
    "        # AUROCo\n",
    "        fpr, tpr, _ = roc_curve(combined_labels, combined_predictions)\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(\n",
    "            combined_labels, combined_predictions\n",
    "        )\n",
    "        current_model_auc = auc(recall, precision)\n",
    "\n",
    "        data.append(\n",
    "            {\n",
    "                \"prediction_edge\": args.edge_type,\n",
    "                \"label_source\": model_file.parents[0].stem,\n",
    "                \"AUPR\": current_model_auc,\n",
    "                \"AUROC\": auc(fpr, tpr),\n",
    "                \"dataset\": \"tune\",\n",
    "                \"lf_num\": lf_num,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    for idx, batch in tqdm.tqdm(enumerate(test_dataset_pt)):\n",
    "        attention_mask = torch.stack(batch[\"attention_mask\"][0]).permute(\n",
    "            1, 0\n",
    "        )  # .cuda()\n",
    "        input_ids = torch.stack(batch[\"input_ids\"][0]).permute(1, 0)  # .cuda()\n",
    "        output = biobert(\n",
    "            attention_mask=attention_mask,\n",
    "            input_ids=input_ids,\n",
    "            labels=batch[\"labels\"].long(),  # .cuda()\n",
    "        )\n",
    "        predictions.append(\n",
    "            torch.nn.functional.softmax(output[1], dim=1)[:, 1]\n",
    "        )  # .cpu())\n",
    "        val_labels.append(batch[\"labels\"])  # .cpu())\n",
    "        validation_loss.append(output[0].mean().item())\n",
    "\n",
    "        combined_labels = torch.cat(val_labels).numpy()\n",
    "        combined_predictions = torch.cat(predictions).detach().numpy()\n",
    "\n",
    "        # AUROCo\n",
    "        fpr, tpr, _ = roc_curve(combined_labels, combined_predictions)\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(\n",
    "            combined_labels, combined_predictions\n",
    "        )\n",
    "        current_model_auc = auc(recall, precision)\n",
    "\n",
    "        data.append(\n",
    "            {\n",
    "                \"prediction_edge\": args.edge_type,\n",
    "                \"label_source\": model_file.parents[0].stem,\n",
    "                \"AUPR\": current_model_auc,\n",
    "                \"AUROC\": auc(fpr, tpr),\n",
    "                \"dataset\": \"test\",\n",
    "                \"lf_num\": lf_num,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame.from_records(data)\n",
    "data_df.to_csv(\n",
    "    f\"{args.edge_type}/{args.edge_type}_total_lf_performance.tsv\", sep=\"\\t\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:snorkeling_full_text]",
   "language": "python",
   "name": "conda-env-snorkeling_full_text-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
