{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator Model Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning models can become over confident in their predictions regardless if the prediction is correct or not. Model calibration is needed to account for this problem. This notebook is designed to use Temperature Scaling to calibrate deep learning models however; it isn't designed executed locally without a gpu. This notebook holds the code in a similar format and was trained on UPenn's computing cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "from temperature_scaling_transformers import ModelWithTemperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Train BioBert as Discriminator Model. Use these two commands to run the model.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--edge_type\",\n",
    "    help=\"The edge type to use to predict the sentences. Valid options are DaG, CbG, CtD, GiG\",\n",
    ")\n",
    "parser.add_argument(\"--best_model\", help=\"The path of the best model to calibrate\")\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.edge_type.lower() == \"dag\":\n",
    "    edge_prediction = \"DaG\"\n",
    "    curated_label = \"curated_dsh\"\n",
    "\n",
    "    validation_file = \"DaG/training_sen/dg_dev_test_encoded_lemmas.tsv\"\n",
    "    validation_labels_file = \"DaG/training_sen/dg_dev_test_candidates_resampling.tsv\"\n",
    "\n",
    "    all_candidates_file = \"DaG/training_sen/all_dg_abstract_encoded_lemmas.tsv\"\n",
    "    output_file = \"DaG/all_dag_candidates.tsv\"\n",
    "\n",
    "    entity_replace_one = \"DISEASE_ENTITY\"\n",
    "    one_replace = \"@DISEASE$\"\n",
    "    entity_replace_two = \"GENE_ENTITY\"\n",
    "    two_replace = \"@GENE$\"\n",
    "\n",
    "if args.edge_type.lower() == \"ctd\":\n",
    "    edge_prediction = \"CtD\"\n",
    "    curated_label = \"curated_ctd\"\n",
    "\n",
    "    validation_file = \"CtD/training_sen/cd_dev_test_encoded_lemmas.tsv\"\n",
    "    validation_labels_file = \"CtD/training_sen/cd_dev_test_candidates_resampling.tsv\"\n",
    "\n",
    "    all_candidates_file = \"CtD/training_sen/all_cd_abstract_encoded_lemmas.tsv\"\n",
    "    output_file = \"CtD/all_ctd_candidates.tsv\"\n",
    "\n",
    "    entity_replace_one = \"COMPOUND_ENTITY\"\n",
    "    one_replace = \"@CHEMICAL$\"\n",
    "    entity_replace_two = \"DISEASE_ENTITY\"\n",
    "    two_replace = \"@DISEASE$\"\n",
    "\n",
    "if args.edge_type.lower() == \"cbg\":\n",
    "    edge_prediction = \"CbG\"\n",
    "    curated_label = \"curated_cbg\"\n",
    "\n",
    "    validation_file = \"CbG/training_sen/cg_dev_test_encoded_lemmas.tsv\"\n",
    "    validation_labels_file = \"CbG/training_sen/cg_dev_test_candidates_resampling.tsv\"\n",
    "\n",
    "    all_candidates_file = \"CbG/training_sen/all_cg_abstract_encoded_lemmas.tsv\"\n",
    "    output_file = \"CbG/all_cbg_candidates.tsv\"\n",
    "\n",
    "    entity_replace_one = \"COMPOUND_ENTITY\"\n",
    "    one_replace = \"@CHEMICAL$\"\n",
    "    entity_replace_two = \"GENE_ENTITY\"\n",
    "    two_replace = \"@GENE$\"\n",
    "\n",
    "if args.edge_type.lower() == \"gig\":\n",
    "    edge_prediction = \"GiG\"\n",
    "    curated_label = \"curated_gig\"\n",
    "\n",
    "    validation_file = \"GiG/training_sen/gg_dev_test_encoded_lemmas.tsv\"\n",
    "    validation_labels_file = \"GiG/training_sen/gg_dev_test_candidates_resampling.tsv\"\n",
    "\n",
    "    all_candidates_file = \"GiG/training_sen/all_gg_abstract_encoded_lemmas.tsv\"\n",
    "    output_file = \"GiG/all_gig_candidates.tsv\"\n",
    "\n",
    "    entity_replace_one = \"GENE_ENTITY\"\n",
    "    one_replace = \"@GENE$\"\n",
    "    entity_replace_two = \"GENE_ENTITY\"\n",
    "    two_replace = \"@GENE$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"../biobert-base-cased-v1.1\", local_files_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the datasets\n",
    "\n",
    "## Validation\n",
    "validation_data = pd.read_csv(validation_file, sep=\"\\t\").rename(\n",
    "    index=str, columns={\"split\": \"dataset\", curated_label: \"labels\"}\n",
    ")\n",
    "dev_split_id = validation_data.dataset.min()\n",
    "test_split_id = validation_data.dataset.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = Dataset.from_pandas(\n",
    "    validation_data.query(f\"dataset=={dev_split_id}\")[[\"parsed_lemmas\", \"labels\"]]\n",
    ")\n",
    "\n",
    "validation_dataset = validation_dataset.map(\n",
    "    lambda x: tokenizer(\n",
    "        \" \".join(\n",
    "            x[\"parsed_lemmas\"]\n",
    "            .replace(entity_replace_one, one_replace)\n",
    "            .replace(entity_replace_two, two_replace)\n",
    "            .split(\"|\")\n",
    "        ),\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=100,\n",
    "        truncation=True,\n",
    "    ),\n",
    "    remove_columns=[\"parsed_lemmas\"],\n",
    ")\n",
    "\n",
    "validation_dataset_pt = DataLoader(validation_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up calibration step for models\n",
    "\n",
    "# Pre calibration\n",
    "biobert = AutoModelForSequenceClassification.from_pretrained(\n",
    "    args.best_model, local_files_only=True, num_labels=2\n",
    ")\n",
    "biobert.eval()\n",
    "val_labels = []\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do I need cuda?\n",
    "biobert = torch.nn.DataParallel(biobert)\n",
    "print(biobert)\n",
    "\n",
    "biobert = biobert.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, batch in tqdm.tqdm(enumerate(validation_dataset_pt)):\n",
    "    attention_mask = torch.stack(batch[\"attention_mask\"][0]).permute(1, 0).cuda()\n",
    "    input_ids = torch.stack(batch[\"input_ids\"][0]).permute(1, 0).cuda()\n",
    "    labels = batch[\"labels\"].long().cuda()\n",
    "    output = biobert(attention_mask=attention_mask, input_ids=input_ids, labels=labels)\n",
    "\n",
    "    # bring back from gpu to save memory\n",
    "    attention_mask.cpu()\n",
    "    input_ids.cpu()\n",
    "    labels.cpu()\n",
    "    output[0].cpu()\n",
    "\n",
    "    val_labels.append(batch[\"labels\"])\n",
    "    predictions.append(\n",
    "        torch.nn.functional.softmax(output[1].detach().cpu(), dim=1)[:, 1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_labels = torch.cat(val_labels).numpy()\n",
    "combined_predictions = torch.cat(predictions).detach().numpy()\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(\n",
    "    combined_labels, combined_predictions, n_bins=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_calibration = pd.DataFrame().from_dict(\n",
    "    dict(true_proportion=prob_true, prediction_proportion=prob_pred)\n",
    ")\n",
    "print(before_calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biobert = biobert.cpu()\n",
    "biobert = ModelWithTemperature(biobert)\n",
    "biobert.cuda()\n",
    "biobert.set_temperature(validation_dataset_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = []\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post calibration\n",
    "for idx, batch in tqdm.tqdm(enumerate(validation_dataset_pt)):\n",
    "    output = biobert(batch)\n",
    "    val_labels.append(batch[\"labels\"])\n",
    "    predictions.append(torch.nn.functional.softmax(output, dim=1)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_labels = torch.cat(val_labels).numpy()\n",
    "combined_predictions = torch.cat(predictions).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(\n",
    "    combined_labels, combined_predictions, n_bins=10\n",
    ")\n",
    "after_calibration = pd.DataFrame().from_dict(\n",
    "    dict(true_proportion=prob_true, prediction_proportion=prob_pred)\n",
    ")\n",
    "print(after_calibration)\n",
    "\n",
    "(\n",
    "    before_calibration.assign(label=\"before_calibration\")\n",
    "    .append(after_calibration.assign(label=\"after_calibration\"))\n",
    "    .to_csv(f\"{edge_prediction}/{edge_prediction}_calibration.tsv\", sep=\"\\t\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Calibrated Model to predict every Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset for all predictions\n",
    "all_data = pd.read_csv(all_candidates_file, sep=\"\\t\")\n",
    "all_dataset = Dataset.from_pandas(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = all_dataset.map(\n",
    "    lambda x: tokenizer(\n",
    "        \" \".join(\n",
    "            x[\"parsed_lemmas\"]\n",
    "            .replace(entity_replace_one, one_replace)\n",
    "            .replace(entity_replace_two, two_replace)\n",
    "            .split(\"|\")\n",
    "        ),\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=100,\n",
    "        truncation=True,\n",
    "    ),\n",
    "    remove_columns=[\"parsed_lemmas\"],\n",
    ")\n",
    "\n",
    "all_dataset_pt = DataLoader(all_dataset, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, \"w\") as out:\n",
    "\n",
    "    outwriter = csv.DictWriter(out, delimiter=\"\\t\", fieldnames=[\"pred\", \"candidate_id\"])\n",
    "    outwriter.writeheader()\n",
    "\n",
    "    # Load the dataset for all predictions\n",
    "    all_data = pd.read_csv(all_candidates_file, sep=\"\\t\", chunksize=100000)\n",
    "\n",
    "    for df_chunk in all_data:\n",
    "        all_dataset = Dataset.from_pandas(df_chunk)\n",
    "\n",
    "        all_dataset = all_dataset.map(\n",
    "            lambda x: tokenizer(\n",
    "                \" \".join(\n",
    "                    x[\"parsed_lemmas\"]\n",
    "                    .replace(entity_replace_one, one_replace)\n",
    "                    .replace(entity_replace_two, two_replace)\n",
    "                    .split(\"|\")\n",
    "                ),\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=100,\n",
    "                truncation=True,\n",
    "            ),\n",
    "            remove_columns=[\"parsed_lemmas\"],\n",
    "        )\n",
    "\n",
    "        all_dataset_pt = DataLoader(all_dataset, batch_size=10)\n",
    "        biobert.cuda()\n",
    "\n",
    "        for batch in tqdm.tqdm(all_dataset_pt):\n",
    "            output = biobert(batch)\n",
    "            predictions = torch.nn.functional.softmax(output, dim=1)[:, 1]\n",
    "            for pred, cand_id in zip(predictions, batch[\"candidate_id\"]):\n",
    "                outwriter.writerow(\n",
    "                    {\"pred\": pred.detach().item(), \"candidate_id\": cand_id.item()}\n",
    "                )\n",
    "\n",
    "        biobert.cpu()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:snorkeling_full_text]",
   "language": "python",
   "name": "conda-env-snorkeling_full_text-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
